# This config is for the `experiment_utils` file (also influences `retrieval_main`)
base:
  master: null
  model_dir: tapas_dual_encoder_proj_256_large # Ensure this is the same as in `retrieval_main`
  tf_random_seed: 1
  train_batch_size: 4 # Adjusted due to memory constraints
  eval_batch_size: 32
  predict_batch_size: 32
  gradient_accumulation_steps: 1

  # Training parameters
  num_train_examples: 5120
  learning_rate: 1.25e-5
  warmup_ratio: 0.01

  # Evaluation parameters
  num_eval_steps: 1000
  eval_throttle_secs: 600
  eval_start_delay_secs: 120

  bert_config_file: tapas_dual_encoder_proj_256_large/bert_config.json
  bert_config_attention_probs_dropout_prob: null
  bert_config_hidden_dropout_prob: null
  bert_config_initializer_range: null
  bert_config_softmax_temperature: null

  # Checkpointing
  save_checkpoints_steps: 100
  keep_checkpoint_max: 3
  keep_checkpoint_every_n_hours: 4.0
  init_checkpoint: tapas_dual_encoder_proj_256_large/model.ckpt
  max_eval_count: 100

# This config is for the main reader script
base:
  input_dir: /home/scur2840/IR2-stefan/outputs/e2e_test
  output_dir: /home/scur2840/IR2-stefan/outputs/e2e_test
  model_dir: null
  task: NQ_RETRIEVAL
  bert_vocab_file: /home/scur2840/tapas_inter_masklm_large/vocab.txt # "this is equal to {reader_model_name}/vocab.txt. Example of the name: `tapas_masklm_large`"
  bert_config_file: /home/scur2840/tapas_inter_masklm_large/bert_config.json
  init_checkpoint: /home/scur2840/tapas_inter_masklm_large/model.ckpt
  tapas_verbosity: null
  test_batch_size: 32
  train_batch_size: 4
  gradient_accumulation_steps: 1
  iterations_per_loop: 1000
  test_mode: false
  tf_random_seed: null
  learning_rate: 1e-6
  max_seq_length: 512
  mode: "predict" # create_data, train, predict_and_evaluate, evaluate, predict
  loop_predict: true
  compression_type: "GZIP"
  verbosity: -1
  reset_position_index_per_cell: false
  prune_columns: false
  reset_output_cls: false
  use_document_title: true
  update_answer_coordinates: true
  drop_rows_to_fit: true
  table_pruning_config_file: null